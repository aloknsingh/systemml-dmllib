# Reference
# The CG algorithm closely follows Algorithm 5.2 in Chapt0ter 5 of
# J. Nocedal and S. Wright. Numerical Optimization. Springer Series in Operations Research and Financial Engineering. Springer, second edition, 2006.
# Note this is borrowed from the systemml https://github.com/SparkTC/systemml/blob/master/system-ml/scripts/algorithms/CsplineCG.dml
# and https://github.com/SparkTC/systemml/blob/master/system-ml/scripts/algorithms/LinearRegCG.dml
# THIS SCRIPT LIBRARY IMPLEMENTS THE CONJUGATE GRADIENT ALGORITHM
#
# INPUT PARAMETERS:
# --------------------------------------------------------------------------------------------
# NAME  TYPE   DEFAULT  MEANING
# --------------------------------------------------------------------------------------------
# 
# tol   Double 0.000001 Tolerance (epsilon); conjugate graduent procedure terminates early if
#                       L2 norm of the beta-residual is less than tolerance * its initial norm
# maxi  Int      0      Maximum number of conjugate gradient iterations, 0 = no maximum
# --------------------------------------------------------------------------------------------
# OUTPUT: The solution vector x
#
# The Log file, when requested, contains the following per-iteration variables in CSV
# format, each line containing triple (NAME, ITERATION, VALUE) with ITERATION = 0 for
# initial values:
#
# NAME                  MEANING
# -------------------------------------------------------------------------------------
# CG_RESIDUAL_NORM      L2-norm of Conj.Grad.residual, which is A %*% beta - t(X) %*% y
#                           where A = t(X) %*% X + diag (lambda), or a similar quantity
# CG_RESIDUAL_RATIO     Ratio of current L2-norm of Conj.Grad.residual over the initial
# -------------------------------------------------------------------------------------
#
#solve Ax = b
#   for CG our formulation is 
#      t(A)Ax = t(A)b // where t is transpose
CGSolver = function (
 matrix[double] A, matrix[double] b,
 int max_iteration, 
 double tolerance,
 String fileLog
) return (matrix[double] x) {

  n = nrow(A)
  if (max_iteration < 0) {
    max_iteration = n 
  }
  if (tolerance < 0) {
    tolerance = 0.000001
  }

  x = matrix (0, rows = n, cols = 1); #/* solution vector x<nx1>*/

  # BEGIN THE CONJUGATE GRADIENT ALGORITHM
  print ("Running the CG algorithm...");

  i = 0
  r = -t(A) %*% b # initial guess x0 = t(0.0)
  p = -r
  norm_r2 = sum (r ^ 2)
  norm_r2_initial = norm_r2
  norm_r2_target = norm_r2_initial * tolerance ^ 2
  print ("||r|| initial value = " + sqrt (norm_r2_initial) + ",  target value = " + sqrt (norm_r2_target));
  log_str = "CG_RESIDUAL_NORM,0," + sqrt (norm_r2_initial)
  log_str = append (log_str, "CG_RESIDUAL_RATIO,0,1.0")

  while (i < max_iteration & norm_r2 > norm_r2_target) {
    q = t(A) %*% (A %*% p)
    #/*q = q + lambda * p*/
    a = norm_r2 / sum (p*q)
    x = x + a*p
    r = r + a*q
    old_norm_r2 = norm_r2
    norm_r2 = sum(r^2)
    p = -r + (norm_r2/ old_norm_r2)*p
    i = i + 1
    print ("Iteration " + i + ":  ||r|| / ||r init|| = " + sqrt (norm_r2 / norm_r2_initial))
    log_str = append (log_str, "CG_RESIDUAL_NORM,"  + i + "," + sqrt (norm_r2))
    log_str = append (log_str, "CG_RESIDUAL_RATIO," + i + "," + sqrt (norm_r2 / norm_r2_initial))
  }
  if (i >= max_iteration) {
    print ("Warning: the maximum number of iterations has been reached.")
  }

  print ("The CG algorithm is done.")
  # END THE CONJUGATE GRADIENT ALGORITHM

  if (fileLog != " ") {
    write (log_str, fileLog);
  } else {
    print("log_str:" + log_str)
  }
}



