#-------------------------------------------------------------
# IBM Confidential
# OCO Source Materials
# (C) Copyright IBM Corp. 2010, 2013
# The source code for this program is not published or
# otherwise divested of its trade secrets, irrespective of
# what has been deposited with the U.S. Copyright Office.
#-------------------------------------------------------------
#
# THIS SCRIPT SOLVES CUBIC SPLINE INTERPOLATION USING THE CONJUGATE GRADIENT ALGORITHM
#
# INPUT PARAMETERS:
# --------------------------------------------------------------------------------------------
# NAME  TYPE   DEFAULT  MEANING
# --------------------------------------------------------------------------------------------
# X     String  ---     Location (on HDFS) to read the 1-column matrix of x values knots
# Y     String  ---     Location (on HDFS) to read the 1-column matrix of corresponding y values knots
# O     String  ---     Location to store the $k_{i}$ -file for the calculated k vectors. the default is to print it to the standard output
# Log   String  " "     Location to store iteration-specific variables for monitoring and debugging purposes
# 
# tol   Double 0.000001 Tolerance (epsilon); conjugate graduent procedure terminates early if
#                       L2 norm of the beta-residual is less than tolerance * its initial norm
# maxi  Int      0      Maximum number of conjugate gradient iterations, 0 = no maximum
# fmt   String "text"   Matrix file output format, such as `text`,`mm`, or `csv`
# --------------------------------------------------------------------------------------------
# OUTPUT: Matrix of k parameters (the betas) 
#
# The Log file, when requested, contains the following per-iteration variables in CSV
# format, each line containing triple (NAME, ITERATION, VALUE) with ITERATION = 0 for
# initial values:
#
# NAME                  MEANING
# -------------------------------------------------------------------------------------
# CG_RESIDUAL_NORM      L2-norm of Conj.Grad.residual, which is A %*% beta - t(X) %*% y
#                           where A = t(X) %*% X + diag (lambda), or a similar quantity
# CG_RESIDUAL_RATIO     Ratio of current L2-norm of Conj.Grad.residual over the initial
# -------------------------------------------------------------------------------------
#
# HOW TO INVOKE THIS SCRIPT - EXAMPLE:
# hadoop jar SystemML.jar -f CsplineCG.dml -nvargs X=INPUT_DIR/X Y=INPUT_DIR/Y B=OUTPUT_DIR/B
#     O=OUTPUT_DIR/Out icpt=2 reg=1.0 tol=0.001 maxi=100 fmt=csv Log=OUTPUT_DIR/log
# hadoop jar SystemML.jar -f CsplineCG.dml -nvargs X=INPUT_DIR/X Y= NPUT_DIR/Y O=OUTPUT_DIR/Out
# tol=0.001 maxi=100 fmt=csv Log=OUTPUT_DIR/log
                      



#Assumptions: 
# - The inputs xs are monotonically increasing, 
# - there is no duplicates points in x

#Algorithms: It implement the https://en.wikipedia.org/wiki/Spline_interpolation#Algorithm_to_find_the_interpolating_cubic_spline
#it usages natural spline with q1''(x0) == qn''(xn) == 0.0



##BEGIN Main Func
fileX = $X;
fileY = $Y;
fileO = $O;
fileLog = ifdef ($Log, " ");
fmtO = ifdef ($fmt, "csv");

tolerance = ifdef ($tol, 0.000001);      # $tol=0.000001;
max_iteration = ifdef ($maxi, 0);        # $maxi=0;

print ("BEGIN CUBIC SPLINE SCRIPT");

print ("Reading X and Y ...");
xs = read (fileX);
ys = read (fileY);

print("Calculating Ks ...")
ks = calcKnotsDerivKs(xs, ys)
print("Writing Ks ...")
write (ks, fileO, format=fmtO);

print("Interpolating ...")
x = 4.5
y = interpSpline(x, xs, ys, ks)

print ("END CUBIC SPLINE REGRESSION SCRIPT");

##END Main Func


/*
 *  #given X<nx1> and corresponding Y<nx1> values for the function. where each (xi,yi) represents a knot.
 * # it calculates the first derivates i.e k of the interpolated polynomial 
 */
calcKnotsDerivKs = function (
  matrix[double] X, matrix[double] Y,
  int max_iteration,
  double tolerance,
  String fileLog
  
) return (matrix[double] K) {
    nx = nrow(X)
    ny = nrow(Y)
    if (nx != ny) {
      stop("X and Y vectors are of different size")
    }
    n = nx
    A = matrix(0.0, n, n)
    b = matrix(0.0, n, 1)
 
    print("ALOK1" + nx)
    for (i in 2:n-1) {
      A[i,i-1] = 1/(X[i, 1] - X[i-1, 1])
      A[i,i] = 2 * (1/(X[i, 1] - X[i-1, 1]) + 1/(X[i+1, 1] - X[i, 1]))
      A[i,i+1] = 1/(X[i+1, 1] - X[i, 1])
      b[i,1] = 3* ( (Y[i, 1] - Y[i-1, 1])/((X[i, 1] - X[i-1, 1])*(X[i, 1] - X[i-1, 1])) + (Y[i+1, 1] - Y[i, 1])/((X[i+1, 1] - X[i, 1])*(X[i+1, 1] - X[i, 1])) )
    }

 print("ALOK2")
    A[1, 1] = 2/(X[2,1] - X[1,1])
    A[1, 2] = 1/(X[2,1] - X[1,1])
    b[1, 1] = 3* (Y[2, 1] - Y[1, 1]) / ((X[2,1] - X[1,1])*(X[2,1] - X[1,1]))
    
     print("ALOK3")
    A[n, n-1] = 1/(X[n,1] - X[n-1,1])
    A[n, n] = 2/(X[n,1] - X[n-1,1])
    b[n, 1] = 3*(Y[n, 1] - Y[n-1, 1]) / ((X[n,1] - X[n-1,1])*(X[n,1] - X[n-1,1]))


    # solve Ax = b for x vector and assign it to K
    K = CGSolver(A, b,
                 max_iteration, tolerance, fileLog)
   

}

/*
 * #given the X<nx1> and Y<nx1> n sample points and K (the first derivative of the interp polynomial), it calculate the 
 * #  y for the given x using the cubic spline interpolation
 */
interpSpline = function(
  double x, matrix[double] X, matrix[double] Y, matrix[double] K
) return (double q) {

  /* first find the right knots for interpolation */
  i = 1
  while(as.scalar(X[i,1]) < x) { /* @NOTE: may be better to do the binary search here*/
    i = i+1
  }

  /* calc the y as per the algo docs*/
  t = (x - X[i-1,1]) / ( X[i,1] - X[i-1,1])

  a =  K[i-1,1]*(X[i,1]-X[i-1,1]) - (Y[i,1]-Y[i-1,1])
  b = -K[i,1]*(X[i,1]-X[i-1,1]) + (Y[i,1]-Y[i-1,1])

  qm = (1-t)*Y[i-1,1] + t*Y[i,1] + t*(1-t)*(a*(1-t)+b*t)

  q = as.scalar(qm)

}

 
#solve Ax = b
#   for CG our formulation is 
#      t(A)Ax = t(A)b // where t is transpose
CGSolver = function (
 matrix[double] A, matrix[double] b,
 int max_iteration, 
 double tolerance,
 String fileLog
) return (matrix[double] x) {

  n = nrow(A)
  if (max_iteration < 0) {
    max_iteration = n 
  }
  if (tolerance < 0) {
    tolerance = 0.000001
  }

  x = matrix (0, rows = n, cols = 1); #/* solution vector x<nx1>*/

  # BEGIN THE CONJUGATE GRADIENT ALGORITHM
  print ("Running the CG algorithm...");

  i = 0
  r = -t(A) %*% b # initial guess x0 = t(0.0)
  p = -r
  norm_r2 = sum (r ^ 2)
  norm_r2_initial = norm_r2
  norm_r2_target = norm_r2_initial * tolerance ^ 2
  print ("||r|| initial value = " + sqrt (norm_r2_initial) + ",  target value = " + sqrt (norm_r2_target));
  log_str = "CG_RESIDUAL_NORM,0," + sqrt (norm_r2_initial)
  log_str = append (log_str, "CG_RESIDUAL_RATIO,0,1.0")

  while (i < max_iteration & norm_r2 > norm_r2_target) {
    q = t(A) %*% (A %*% p)
    #/*q = q + lambda * p*/
    a = norm_r2 / sum (p*q)
    x = x + a*p
    r = r + a*q
    old_norm_r2 = norm_r2
    norm_r2 = sum(r^2)
    p = -r + (norm_r2/ old_norm_r2)*p
    i = i + 1
    print ("Iteration " + i + ":  ||r|| / ||r init|| = " + sqrt (norm_r2 / norm_r2_initial))
    log_str = append (log_str, "CG_RESIDUAL_NORM,"  + i + "," + sqrt (norm_r2))
    log_str = append (log_str, "CG_RESIDUAL_RATIO," + i + "," + sqrt (norm_r2 / norm_r2_initial))
  }
  if (i >= max_iteration) {
    print ("Warning: the maximum number of iterations has been reached.")
  }

  print ("The CG algorithm is done.")
  # END THE CONJUGATE GRADIENT ALGORITHM

  if (fileLog != " ") {
    write (log_str, fileLog);
  } else {
    print("log_str:" + log_str)
  }
}

## /* test5: y = sin(x)  */
## str_xs = "1 2 3 4 5 6 7 8 9 10"
## str_ys = "0.8414710  0.9092974  0.1411200 -0.7568025 -0.9589243 -0.2794155 0.6569866  0.9893582  0.4121185 -0.5440211"

## xs = matrix(str_xs, rows = 10, cols = 1)
## ys = matrix(str_ys, rows = 10, cols = 1)
## ks = calcKnotsDerivKs(xs, ys)
## x = 4.5
## y = interpSpline(x, xs, ys, ks)
## exp_y = sin(x);
## print("{  X=["+str_xs + "]")
## print("   Y=["+str_ys + "]")
## print("   expected => sin(x=" + x + ") = " + exp_y)
## print("   cspline(x="+x+") => "+ y + "}")
## print("   error => (expected-cspline)/expected = " + (exp_y-y)/exp_y )


